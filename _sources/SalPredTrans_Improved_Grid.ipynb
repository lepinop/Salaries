{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e349b18b",
   "metadata": {},
   "source": [
    "# **Modelo original: SalPred‑Trans — Transformer tabular cuantílico + Conformal Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd66868",
   "metadata": {},
   "source": [
    "**SalPred-Trans** es un modelo de **regresión tabular basado en Transformers** para predecir salarios (USD, 2025). Convierte variables categóricas y numéricas en *tokens* y aprende **interacciones complejas** sin mucha ingeniería de atributos. Se entrena con **GridSearchCV** optimizando **RMSE** y reporta métricas en escala original y logarítmica. Además, entrega **intervalos de predicción calibrados** con *Conformal Prediction* para cuantificar la incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291765e",
   "metadata": {},
   "source": [
    "## 1. Importaciones y configuración inicial\n",
    "Aquí cargamos todas las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f6c4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup OK.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 0) Setup\n",
    "import os, sys, time, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, os.getcwd())\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    torch.set_num_threads(1)\n",
    "    torch.manual_seed(RANDOM_STATE)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Setup OK.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3c62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, salpred_components\n",
    "importlib.reload(salpred_components)\n",
    "from salpred_components import SalPredPreprocessor, SalPredTransRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580ae3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "Memory(\"./_salpred_cache\").clear(warn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2f824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso del archivo .py salpred_components:\n",
    "from salpred_components import SalPredPreprocessor, SalPredTransRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import Memory\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907faf9",
   "metadata": {},
   "source": [
    "## 2. Carga de datos y selección de columnas\n",
    "\n",
    "1. Leemos el archivo salaries.csv.\n",
    "2. Definimos variables categóricas (ejemplo: job_title, company_size) y numéricas (ejemplo: salario, work_year).\n",
    "\n",
    "Aquí limpiamos y organizamos el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06f6402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Datos + normalización de títulos + splits \n",
    "DATA_PATH = \"salaries.csv\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(\"No se encontró salaries.csv junto al notebook.\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[df[\"work_year\"] == 2025].copy()\n",
    "\n",
    "def normalize_title(s: str) -> str:\n",
    "    s = str(s).lower().replace('-', ' ').replace('/', ' ')\n",
    "    if 'data scientist' in s: return 'data scientist'\n",
    "    if 'data engineer' in s: return 'data engineer'\n",
    "    if 'data analyst'  in s: return 'data analyst'\n",
    "    if 'machine learning' in s or 'ml engineer' in s: return 'ml engineer'\n",
    "    if 'ai engineer' in s or 'artificial intelligence' in s: return 'ai engineer'\n",
    "    if 'research' in s and ('ml' in s or 'ai' in s): return 'ml researcher'\n",
    "    return s\n",
    "\n",
    "if 'job_title' in df.columns:\n",
    "    df['job_title'] = df['job_title'].map(normalize_title)\n",
    "\n",
    "target_col = \"salary_in_usd\"\n",
    "cat_cols = [\"experience_level\",\"employment_type\",\"job_title\",\n",
    "            \"employee_residence\",\"company_location\",\"company_size\"]\n",
    "num_cols = [\"work_year\",\"remote_ratio\"]\n",
    "\n",
    "X = df[cat_cols + num_cols].copy()\n",
    "y = df[target_col].astype(float).values\n",
    "\n",
    "strata = df[\"experience_level\"] if \"experience_level\" in df.columns else None\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.20, random_state=RANDOM_STATE, stratify=strata)\n",
    "strata_temp = X_temp[\"experience_level\"] if \"experience_level\" in X_temp.columns else None\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=RANDOM_STATE, stratify=strata_temp)\n",
    "strata_train = X_train[\"experience_level\"] if \"experience_level\" in X_train.columns else None\n",
    "X_trn, X_cal, y_trn, y_cal = train_test_split(X_train, y_train, test_size=0.20, random_state=RANDOM_STATE, stratify=strata_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2.5) Limpieza en dos etapas: WIN(S1) -> TRIM(S2) ===\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "GROUPS = [\"company_location\",\"experience_level\"]\n",
    "CLEAN_CAL = True   # aplica también a CAL; VAL/TEST no se tocan\n",
    "\n",
    "def _keys(Xs): \n",
    "    return list(zip(Xs[\"company_location\"], Xs[\"experience_level\"]))\n",
    "\n",
    "def _compute_bounds(X_trn_cur, y_trn_cur, qlo, qhi):\n",
    "    tmp = pd.DataFrame({\"key\": _keys(X_trn_cur), \"y_log\": np.log1p(y_trn_cur)})\n",
    "    g = tmp.groupby(\"key\")[\"y_log\"]\n",
    "    qlo_g = g.quantile(qlo); qhi_g = g.quantile(qhi)\n",
    "    glo_lo = float(tmp[\"y_log\"].quantile(qlo)); glo_hi = float(tmp[\"y_log\"].quantile(qhi))\n",
    "    def _bounds(Xs):\n",
    "        ks = _keys(Xs)\n",
    "        lo = np.array([np.expm1(qlo_g.get(k, glo_lo)) for k in ks], float)\n",
    "        hi = np.array([np.expm1(qhi_g.get(k, glo_hi)) for k in ks], float)\n",
    "        return lo, hi\n",
    "    return _bounds\n",
    "\n",
    "def _winsorize(Xs, ys, bounds_fn):\n",
    "    lo, hi = bounds_fn(Xs)\n",
    "    return Xs, np.minimum(np.maximum(ys, lo), hi)\n",
    "\n",
    "def _trim(Xs, ys, bounds_fn):\n",
    "    lo, hi = bounds_fn(Xs)\n",
    "    keep = (ys >= lo) & (ys <= hi)\n",
    "    removed = int((~keep).sum())\n",
    "    return Xs[keep], ys[keep], removed\n",
    "\n",
    "# --- Etapa 1: WIN(S1) con umbral suave (p.ej. 0.5%–99.5%) ---\n",
    "bounds_s1 = _compute_bounds(X_trn, y_trn, qlo=0.005, qhi=0.995)\n",
    "X_trn, y_trn = _winsorize(X_trn, y_trn, bounds_s1)\n",
    "if CLEAN_CAL: X_cal, y_cal = _winsorize(X_cal, y_cal, bounds_s1)\n",
    "\n",
    "# --- Etapa 2: TRIM(S2) más agresivo (p.ej. 1%–99%) ---\n",
    "bounds_s2 = _compute_bounds(X_trn, y_trn, qlo=0.01, qhi=0.99)  # recalcula con TRN ya winsorizado\n",
    "X_trn, y_trn, rem_trn = _trim(X_trn, y_trn, bounds_s2)\n",
    "if CLEAN_CAL:\n",
    "    X_cal, y_cal, rem_cal = _trim(X_cal, y_cal, bounds_s2)\n",
    "else:\n",
    "    rem_cal = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd6f1c",
   "metadata": {},
   "source": [
    "## 3. Pipeline y GridSearch - Modelo Original\n",
    "Se define el modelo SalPredTrans\n",
    "Aquí encontramos la “mejor versión” del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1) Pipeline + GridSearch (compacto)\n",
    "memory = Memory(\"./_salpred_cache\", verbose=0)\n",
    "\n",
    "prep  = SalPredPreprocessor(cat_cols=cat_cols, num_cols=num_cols, min_freq_rare=80, clip_val=5.0)\n",
    "model = SalPredTransRegressor(\n",
    "    d_model=128, n_heads=8, n_layers=2, dropout=0.1,\n",
    "    lr=1e-3, weight_decay=1e-4,\n",
    "    batch_size=512, warmup_epochs=1, max_epochs=8, patience=2,\n",
    "    lambda_nc=10.0, seed=RANDOM_STATE, verbose=False\n",
    ")\n",
    "pipe = Pipeline([(\"prep\", prep), (\"model\", model)], memory=memory)\n",
    "\n",
    "param_grid = {\n",
    "    \"prep__min_freq_rare\": [80, 120],\n",
    "    \"model__d_model\": [128, 190],\n",
    "    \"model__n_heads\": [8],\n",
    "    \"model__n_layers\": [2, 3],\n",
    "    \"model__lr\": [1e-3, 3e-4],\n",
    "    \"model__dropout\": [0.1, 0.2, 0.3],\n",
    "}\n",
    "KFOLDS = 5\n",
    "N_JOBS = 2\n",
    "cv = KFold(n_splits=KFOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",   #Se optimiza por RMSE\n",
    "    cv=cv,\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd47327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GridSearch fits: 100%|█████████▉| 240/241 [3:30:29<00:52, 52.62s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'model__d_model': 128, 'model__dropout': 0.1, 'model__lr': 0.001, 'model__n_heads': 8, 'model__n_layers': 3, 'prep__min_freq_rare': 80}\n",
      "Tiempo GridSearch (s): 12629.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.2) GridSearch con progreso (si está tqdm) o verbose=3\n",
    "import time, numpy as np\n",
    "\n",
    "use_tqdm = False\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "    import joblib\n",
    "    from contextlib import contextmanager\n",
    "    @contextmanager\n",
    "    def tqdm_joblib(tqdm_object):\n",
    "        class TqdmBatchCompletionCallBack(joblib.parallel.BatchCompletionCallBack):\n",
    "            def __call__(self, *args, **kwargs):\n",
    "                tqdm_object.update(n=self.batch_size)\n",
    "                return super().__call__(*args, **kwargs)\n",
    "        old_cb = joblib.parallel.BatchCompletionCallBack\n",
    "        joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallBack\n",
    "        try:\n",
    "            yield tqdm_object\n",
    "        finally:\n",
    "            joblib.parallel.BatchCompletionCallBack = old_cb\n",
    "            tqdm_object.close()\n",
    "    use_tqdm = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "if use_tqdm:\n",
    "    n_candidates = len(list(ParameterGrid(gs.param_grid)))\n",
    "    # cuenta también el refit del mejor modelo si corresponde\n",
    "    n_fits = KFOLDS * n_candidates + (1 if getattr(gs, \"refit\", True) else 0)\n",
    "    with tqdm_joblib(tqdm(total=n_fits, desc=\"GridSearch fits\")):\n",
    "        gs.fit(X_trn, y_trn)\n",
    "else:\n",
    "    gs.set_params(verbose=3)\n",
    "    gs.fit(X_trn, y_trn)\n",
    "elapsed = time.perf_counter() - t0\n",
    "\n",
    "# ---- Prints adaptativos según scoring ----\n",
    "sc = getattr(gs, \"scoring\", None)\n",
    "if isinstance(sc, str):\n",
    "    is_neg = sc.startswith(\"neg_\")\n",
    "    key = sc.replace(\"neg_\", \"\")\n",
    "else:\n",
    "    is_neg, key = False, \"score\"\n",
    "\n",
    "best = (-gs.best_score_) if is_neg else gs.best_score_\n",
    "\n",
    "print(\"Best params:\", gs.best_params_)\n",
    "print(f\"Tiempo GridSearch (s): {elapsed:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c160ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Validación (VAL) + refit (TRN+VAL) + métricas en log\n",
    "def rmse(y_true, y_pred):\n",
    "    try:\n",
    "        return mean_squared_error(y_true, y_pred, squared=False)\n",
    "    except TypeError:\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "best = gs.best_estimator_\n",
    "best.named_steps[\"model\"].batch_size = 2048\n",
    "\n",
    "y_val_pred = best.predict(X_val)\n",
    "MAE_val  = mean_absolute_error(y_val, y_val_pred)\n",
    "RMSE_val = rmse(y_val, y_val_pred)\n",
    "MAPE_val = np.mean(np.abs((y_val - y_val_pred)/np.maximum(1e-9, np.abs(y_val))))*100\n",
    "R2_val   = r2_score(y_val, y_val_pred)\n",
    "\n",
    "Xd_val = best.named_steps[\"prep\"].transform(X_val)\n",
    "_, qM_val, _ = best.named_steps[\"model\"].predict_quantiles(Xd_val)\n",
    "yl = np.log1p(y_val); yhatl = np.log1p(qM_val)\n",
    "rmse_log = np.sqrt(np.mean((yl - yhatl)**2))\n",
    "mae_log  = np.mean(np.abs(yl - yhatl))\n",
    "r2_log   = 1 - np.sum((yl - yhatl)**2) / np.sum((yl - yl.mean())**2)\n",
    "\n",
    "from sklearn.pipeline import Pipeline as _Pipeline\n",
    "pipe_final = _Pipeline([(\"prep\", SalPredPreprocessor(cat_cols=cat_cols, num_cols=num_cols)),\n",
    "                        (\"model\", SalPredTransRegressor())], memory=memory)\n",
    "pipe_final.set_params(**gs.best_params_)\n",
    "_ = pipe_final.fit(pd.concat([X_trn, X_val]), np.concatenate([y_trn, y_val]))\n",
    "pipe_final.named_steps[\"model\"].batch_size = 4096\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5213ce56",
   "metadata": {},
   "source": [
    "## 4. Test \n",
    "Se testea el modelo SalPredTrans en escala usd y logarítmica, se muestran los resultados conrrespondientes en la escala original para poder comparar justamente con los modelos tradicionales desarrollados previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | MAE=411  RMSE=757  MAPE=0.39%\n"
     ]
    }
   ],
   "source": [
    "# 4.1) TEST punto + log\n",
    "y_tst_pred = pipe_final.predict(X_test)\n",
    "MAE  = mean_absolute_error(y_test, y_tst_pred)\n",
    "RMSE = rmse(y_test, y_tst_pred)\n",
    "MAPE = np.mean(np.abs((y_test - y_tst_pred)/np.maximum(1e-9, np.abs(y_test))))*100\n",
    "print(f\"TEST | MAE={MAE:,.0f}  RMSE={RMSE:,.0f}  MAPE={MAPE:.2f}%\") #correspondientes a escala en usd\n",
    "\n",
    "Xd_test = pipe_final.named_steps[\"prep\"].transform(X_test)\n",
    "_, qM_test, _ = pipe_final.named_steps[\"model\"].predict_quantiles(Xd_test)\n",
    "ylt = np.log1p(y_test); yhatlt = np.log1p(qM_test)\n",
    "rmse_log_t = np.sqrt(np.mean((ylt - yhatlt)**2))\n",
    "mae_log_t  = np.mean(np.abs(ylt - yhatlt))\n",
    "r2_log_t   = 1 - np.sum((ylt - yhatlt)**2) / np.sum((ylt - ylt.mean())**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a87af4",
   "metadata": {},
   "source": [
    "## 5. Conformal Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83056726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized CQR | Coverage=0.900 | Avg width=2,489 | Interval Score=2,511\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8) Conformal CQR normalizado\n",
    "alpha = 0.10\n",
    "\n",
    "Xd_cal = pipe_final.named_steps[\"prep\"].transform(X_cal)\n",
    "qL_cal, qM_cal, qU_cal = pipe_final.named_steps[\"model\"].predict_quantiles(Xd_cal)\n",
    "\n",
    "scale_cal = np.maximum(qM_cal - qL_cal, qU_cal - qM_cal)\n",
    "scale_cal = np.maximum(scale_cal, 1e-6)\n",
    "\n",
    "scores = np.maximum((qL_cal - y_cal)/scale_cal, (y_cal - qU_cal)/scale_cal)\n",
    "scores = np.sort(scores)\n",
    "m = len(scores)\n",
    "k = int(np.ceil((1 - alpha) * (m + 1))) - 1\n",
    "k = int(np.clip(k, 0, m-1))\n",
    "qhat = float(scores[k])\n",
    "\n",
    "Xd_test = pipe_final.named_steps[\"prep\"].transform(X_test)\n",
    "qL_t, qM_t, qU_t = pipe_final.named_steps[\"model\"].predict_quantiles(Xd_test)\n",
    "s_t = np.maximum(qM_t - qL_t, qU_t - qM_t); s_t = np.maximum(s_t, 1e-6)\n",
    "L = qL_t - qhat * s_t\n",
    "U = qU_t + qhat * s_t\n",
    "\n",
    "coverage  = np.mean((y_test >= L) & (y_test <= U))\n",
    "avg_width = np.mean(U - L)\n",
    "def interval_score(y, L, U, alpha=0.10):\n",
    "    return (U-L) + (2/alpha)*((L - y)*(y < L)) + (2/alpha)*((y - U)*(y > U))\n",
    "IS = np.mean(interval_score(y_test, L, U, alpha))\n",
    "print(f\"Normalized CQR | Coverage={coverage:.3f} | Avg width={avg_width:,.0f} | Interval Score={IS:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407c81d",
   "metadata": {},
   "source": [
    "## 6. Evaluación y métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c2244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86615e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.1) Construye df_usd (TRAIN/TEST) en USD\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def rmse(y, yhat):\n",
    "    try:\n",
    "        return mean_squared_error(y, yhat, squared=False)\n",
    "    except TypeError:\n",
    "        return np.sqrt(mean_squared_error(y, yhat))\n",
    "\n",
    "def mape_pct(y, yhat):\n",
    "    y = np.asarray(y, float); yhat = np.asarray(yhat, float)\n",
    "    return np.mean(np.abs((y - yhat) / np.maximum(1e-9, np.abs(y)))) * 100\n",
    "\n",
    "# Predicciones para TRAIN y TEST\n",
    "est_train  = gs.best_estimator_           # refitteado en X_trn por GridSearchCV\n",
    "y_trn_pred = est_train.predict(X_trn)\n",
    "\n",
    "est_test   = pipe_final                   # entrenado en TRN+VAL\n",
    "y_tst_pred = est_test.predict(X_test)\n",
    "\n",
    "# DataFrame para la tabla\n",
    "df_usd = pd.DataFrame([{\n",
    "    \"Modelo\": \"SalPred-Trans\",\n",
    "    \"Train_RMSE\": rmse(y_trn, y_trn_pred),\n",
    "    \"Train_MAE\":  mean_absolute_error(y_trn, y_trn_pred),\n",
    "    \"Train_MSE\":  float(mean_squared_error(y_trn, y_trn_pred)),\n",
    "    \"Train_MAPE\": mape_pct(y_trn, y_trn_pred),\n",
    "\n",
    "    \"Test_RMSE\": rmse(y_test, y_tst_pred),\n",
    "    \"Test_MAE\":  mean_absolute_error(y_test, y_tst_pred),\n",
    "    \"Test_MSE\":  float(mean_squared_error(y_test, y_tst_pred)),\n",
    "    \"Test_MAPE\": mape_pct(y_test, y_tst_pred),\n",
    "}]).set_index(\"Modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48d409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_38342 thead th {\n",
       "  background-color: #b22222;\n",
       "  color: white;\n",
       "  font-weight: bold;\n",
       "  border: 1px solid #b22222;\n",
       "}\n",
       "#T_38342 caption {\n",
       "  caption-side: top;\n",
       "  font-size: 16px;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_38342_row0_col0, #T_38342_row0_col1, #T_38342_row0_col2, #T_38342_row0_col3, #T_38342_row0_col4, #T_38342_row0_col5, #T_38342_row0_col6, #T_38342_row0_col7 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "  text-align: center;\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_38342\" id=\"T_usd\">\n",
       "  <caption>Comparación de Modelos – Train vs Test (MSE, RMSE, MAE, MAPE en escala original USD)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_38342_level0_col0\" class=\"col_heading level0 col0\" >Train_RMSE</th>\n",
       "      <th id=\"T_38342_level0_col1\" class=\"col_heading level0 col1\" >Train_MAE</th>\n",
       "      <th id=\"T_38342_level0_col2\" class=\"col_heading level0 col2\" >Train_MSE</th>\n",
       "      <th id=\"T_38342_level0_col3\" class=\"col_heading level0 col3\" >Train_MAPE</th>\n",
       "      <th id=\"T_38342_level0_col4\" class=\"col_heading level0 col4\" >Test_RMSE</th>\n",
       "      <th id=\"T_38342_level0_col5\" class=\"col_heading level0 col5\" >Test_MAE</th>\n",
       "      <th id=\"T_38342_level0_col6\" class=\"col_heading level0 col6\" >Test_MSE</th>\n",
       "      <th id=\"T_38342_level0_col7\" class=\"col_heading level0 col7\" >Test_MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Modelo</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_38342_level0_row0\" class=\"row_heading level0 row0\" >SalPred-Trans</th>\n",
       "      <td id=\"T_38342_row0_col0\" class=\"data row0 col0\" >868</td>\n",
       "      <td id=\"T_38342_row0_col1\" class=\"data row0 col1\" >420</td>\n",
       "      <td id=\"T_38342_row0_col2\" class=\"data row0 col2\" >753,737</td>\n",
       "      <td id=\"T_38342_row0_col3\" class=\"data row0 col3\" >0.31%</td>\n",
       "      <td id=\"T_38342_row0_col4\" class=\"data row0 col4\" >757</td>\n",
       "      <td id=\"T_38342_row0_col5\" class=\"data row0 col5\" >411</td>\n",
       "      <td id=\"T_38342_row0_col6\" class=\"data row0 col6\" >572,793</td>\n",
       "      <td id=\"T_38342_row0_col7\" class=\"data row0 col7\" >0.39%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20455d348b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#6.2) Tabla USD (solo TRAIN/TEST) — estilo \"Reds\"\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "HEADER = \"#b22222\"\n",
    "CAPTION_USD = \"Comparación de Modelos – Train vs Test (MSE, RMSE, MAE, MAPE en escala original USD)\"\n",
    "\n",
    "def _apply_header_theme(styler, caption, header_color=HEADER):\n",
    "    return (styler\n",
    "            .set_caption(caption)\n",
    "            .set_table_styles([\n",
    "                {\"selector\":\"thead th\",\n",
    "                 \"props\":[(\"background-color\", header_color), (\"color\",\"white\"),\n",
    "                          (\"font-weight\",\"bold\"), (\"border\", f\"1px solid {header_color}\")]},\n",
    "                {\"selector\":\"caption\",\n",
    "                 \"props\":[(\"caption-side\",\"top\"), (\"font-size\",\"16px\"),\n",
    "                          (\"font-weight\",\"bold\")]}\n",
    "            ])\n",
    "            .set_properties(**{\"text-align\":\"center\",\"white-space\":\"nowrap\"}))\n",
    "\n",
    "if \"df_usd\" in globals() and isinstance(df_usd, pd.DataFrame) and not df_usd.empty:\n",
    "    df_usd_disp = df_usd.copy()\n",
    "\n",
    "    err_cols_usd_all = [\n",
    "        \"Train_RMSE\",\"Train_MAE\",\"Train_MSE\",\"Train_MAPE\",\n",
    "        \"Test_RMSE\",\"Test_MAE\",\"Test_MSE\",\"Test_MAPE\"\n",
    "    ]\n",
    "    err_cols_usd = [c for c in err_cols_usd_all if c in df_usd_disp.columns]\n",
    "\n",
    "    # Formatos (miles y %)\n",
    "    fmt_usd = {}\n",
    "    for c in df_usd_disp.columns:\n",
    "        if any(k in c for k in [\"RMSE\",\"MAE\",\"MSE\"]):\n",
    "            fmt_usd[c] = \"{:,.0f}\"\n",
    "    if \"Train_MAPE\" in df_usd_disp.columns: fmt_usd[\"Train_MAPE\"] = \"{:.2f}%\"\n",
    "    if \"Test_MAPE\"  in df_usd_disp.columns: fmt_usd[\"Test_MAPE\"]  = \"{:.2f}%\"\n",
    "\n",
    "    styled_usd = (df_usd_disp.style\n",
    "                  .format(fmt_usd)\n",
    "                  .background_gradient(cmap=\"Reds\", subset=err_cols_usd, axis=0)\n",
    "                  .set_table_attributes('id=\"T_usd\"'))\n",
    "    styled_usd = _apply_header_theme(styled_usd, CAPTION_USD)\n",
    "    try: styled_usd = styled_usd.hide_index()\n",
    "    except: pass\n",
    "    display(styled_usd)\n",
    "else:\n",
    "    print(\"[aviso] df_usd no existe o está vacío → no se mostrará la tabla USD.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e019f08",
   "metadata": {},
   "source": [
    "En USD, SalPred-Trans muestra buena generalización, sin señales de sobreajuste; incluso el RMSE/MAE de test es levemente mejor. La coherencia \n",
    "RMSE\n",
    "2\n",
    "≈\n",
    "MSE\n",
    "RMSE\n",
    "2\n",
    "≈MSE confirma estabilidad numérica. El aumento del MAPE en test indica mayor error relativo (probablemente por más casos de salario bajo), mientras que en términos absolutos el modelo mantiene un error medio cercano a $411 y un error típico (RMSE) alrededor de $757 en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7b8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ce9c2 thead th {\n",
       "  background-color: #b22222;\n",
       "  color: white;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_ce9c2 caption {\n",
       "  caption-side: top;\n",
       "  font-size: 16px;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_ce9c2_row0_col0 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_ce9c2_row0_col1, #T_ce9c2_row0_col2 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ce9c2\">\n",
       "  <caption>Intervalos Conformales — TEST</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ce9c2_level0_col0\" class=\"col_heading level0 col0\" >Coverage</th>\n",
       "      <th id=\"T_ce9c2_level0_col1\" class=\"col_heading level0 col1\" >Avg_width</th>\n",
       "      <th id=\"T_ce9c2_level0_col2\" class=\"col_heading level0 col2\" >Interval_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Split</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ce9c2_level0_row0\" class=\"row_heading level0 row0\" >TEST (conformal CQR norm)</th>\n",
       "      <td id=\"T_ce9c2_row0_col0\" class=\"data row0 col0\" >0.900</td>\n",
       "      <td id=\"T_ce9c2_row0_col1\" class=\"data row0 col1\" >2,489</td>\n",
       "      <td id=\"T_ce9c2_row0_col2\" class=\"data row0 col2\" >2,511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2045d2bcf40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def _interval_score_vec(y, L, U, alpha):\n",
    "    under = np.maximum(L - y, 0.0)\n",
    "    over  = np.maximum(y - U, 0.0)\n",
    "    return (U - L) + (2.0/alpha) * (under + over)\n",
    "\n",
    "coverage  = float(np.mean((y_test >= L) & (y_test <= U)))\n",
    "avg_width = float(np.mean(U - L))\n",
    "IS        = float(np.mean(_interval_score_vec(y_test, L, U, alpha)))\n",
    "\n",
    "df_conf = pd.DataFrame([{\n",
    "    \"Split\": \"TEST (conformal CQR norm)\",\n",
    "    \"Coverage\": coverage,\n",
    "    \"Avg_width\": avg_width,\n",
    "    \"Interval_Score\": IS\n",
    "}]).set_index(\"Split\")\n",
    "\n",
    "# --- estilo \"Reds\" con header #b22222 ---\n",
    "HEADER = \"#b22222\"\n",
    "fmt = {\"Coverage\":\"{:.3f}\", \"Avg_width\":\"{:,.0f}\", \"Interval_Score\":\"{:,.0f}\"}\n",
    "\n",
    "styled_conf = (df_conf.style\n",
    "    .format(fmt)\n",
    "    .set_caption(\"Intervalos Conformales — TEST\")\n",
    "    .set_table_styles([\n",
    "        {\"selector\":\"thead th\",\n",
    "         \"props\":[(\"background-color\", HEADER), (\"color\",\"white\"), (\"font-weight\",\"bold\")]},\n",
    "        {\"selector\":\"caption\",\n",
    "         \"props\":[(\"caption-side\",\"top\"), (\"font-size\",\"16px\"), (\"font-weight\",\"bold\")]}\n",
    "    ])\n",
    "    .background_gradient(cmap=\"Reds\", subset=[\"Avg_width\",\"Interval_Score\"], axis=0)\n",
    "    .apply(lambda s: ['background-color: white'] * len(s), subset=[\"Coverage\"])\n",
    ")\n",
    "display(styled_conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418ef62e",
   "metadata": {},
   "source": [
    "**Intervalos (TEST):** Con **coverage = 0.900**, los intervalos están calibrados exactamente al objetivo \\(1-\\alpha = 0.90\\). El **ancho promedio = 2,489** USD es coherente con el desempeño del modelo en test, y el **Interval Score = 2,511** queda apenas por encima del ancho, señal de pocas violaciones y penalidad baja. En conjunto, son **intervalos bien calibrados y de amplitud razonable**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b91a5",
   "metadata": {},
   "source": [
    "## Modelo original vs. Tradicionales - Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a3b064",
   "metadata": {},
   "source": [
    "SalPred-Trans lidera la comparación: obtiene el mejor RMSE (757) y mejor MSE (572,793) en test, con MAE 411 y MAPE 0.39%, logrando el balance más sólido entre error medio y control de outliers. \n",
    "Detrás, el MLP destaca en MAE (348, el más bajo) y comparte el MAPE top (~0.30%) con XGB (que, no obstante, queda lejos en RMSE: 2,557 y MAE 447). Más atrás aparecen KNN (RMSE 8,698, MAE 2,720), SVR (RMSE 10,908, MAE 8,987), DecisionTree (RMSE 52,958, MAE 35,319), y, ya bastante rezagados en error cuadrático, Ridge (RMSE 89,435) y Lasso (RMSE 111,077). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
